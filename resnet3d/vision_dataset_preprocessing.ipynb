{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artmed/anaconda3/envs/pytorch/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, cv2, copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorchvideo.data.encoded_video import EncodedVideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the dataset folder\n",
    "dir_10s = r'/home/artmed/Documents/Data_processed'\n",
    "names_vision = ['C+', 'C-', 'PN', 'EA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_vision = pd.DataFrame(columns=['subject_name', 'video_path', 'label'])\n",
    "bad_videos = []\n",
    "for name in names_vision:\n",
    "    g = os.walk(os.path.join(dir_10s, name))\n",
    "\n",
    "    for path,dir_list,file_list in g:\n",
    "        for file_name in file_list:\n",
    "            video_path = os.path.join(path, file_name)\n",
    "            try:\n",
    "                video = EncodedVideo.from_path(video_path)\n",
    "                subject_name = path.split('Data_processed')[1]\n",
    "                label = name\n",
    "                df_vision.loc[len(df_vision.index)] = [subject_name, video_path, label]\n",
    "            except:\n",
    "                path_bad_video = video_path.split('Data_processed')[1]\n",
    "                print(\"Bad video: {}, We can't open it!\".format(path_bad_video))\n",
    "                bad_videos.append(path_bad_video)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bad_videos), len(df_vision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(df_vision.label.value_counts())\n",
    "df_C_plus = df_vision[df_vision['label'] == 'C+']\n",
    "df_C_minus = df_vision[df_vision['label'] == 'C-']\n",
    "df_PN = df_vision[df_vision['label'] == 'PN']\n",
    "df_EA = df_vision[df_vision['label'] == 'EA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Handle the data imbalance problem\n",
    "# Random drop some samples for EA class\n",
    "remove_n = 1461\n",
    "drop_indices = np.random.choice(df_EA.index, remove_n, replace=False)\n",
    "df_EA_modified = df_EA.drop(drop_indices)\n",
    "\n",
    "# Keep the C+ class as it is\n",
    "df_C_plus_modified = df_C_plus\n",
    "# # Random drop some samples for C+ class\n",
    "# remove_n = 6\n",
    "# drop_indices = np.random.choice(df_C_plus.index, remove_n, replace=False)\n",
    "# df_C_plus_modified = df_C_plus.drop(drop_indices)\n",
    "\n",
    "# Oversample the C- class for 63 times\n",
    "df_C_minus_modified = pd.concat([df_C_minus]*63, ignore_index=True)\n",
    "\n",
    "# Oversample the PN class for 30 times\n",
    "df_PN_modified = pd.concat([df_PN]*30, ignore_index=True)\n",
    "\n",
    "df_vision_modified = pd.concat([df_C_plus_modified, df_C_minus_modified, df_PN_modified, df_EA_modified], ignore_index=True)\n",
    "print(df_vision_modified.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split the dataset into train and val based on the label\n",
    "df_train, df_val = train_test_split(df_vision_modified, test_size=0.2, stratify=df_vision_modified['label'], random_state=42)\n",
    "print(df_train.label.value_counts())\n",
    "print(df_val.label.value_counts())\n",
    "\n",
    "# Store the train and val dataset\n",
    "df_train.to_csv('train.csv', index=False)\n",
    "df_val.to_csv('val.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Old way to split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir_train = os.path.join(dir_vision, 'train')\n",
    "dir_val = os.path.join(dir_vision, 'val')\n",
    "if not os.path.exists(dir_train): os.mkdir(dir_train)\n",
    "if not os.path.exists(dir_val): os.mkdir(dir_val)\n",
    "\n",
    "durations = []\n",
    "for name in names_vision:\n",
    "    g = os.walk(os.path.join(dir_10s, name))\n",
    "    dir_target_train = os.path.join(dir_train, name)\n",
    "    dir_target_val = os.path.join(dir_val, name)\n",
    "    if not os.path.exists(dir_target_train): os.mkdir(dir_target_train)\n",
    "    if not os.path.exists(dir_target_val): os.mkdir(dir_target_val)\n",
    "\n",
    "    paths_video = []\n",
    "    for path,dir_list,file_list in g:\n",
    "        for file_name in file_list:\n",
    "            path_video = os.path.join(path, file_name)\n",
    "            paths_video.append(path_video)\n",
    "    for num, path_video in enumerate(paths_video):\n",
    "        cap = cv2.VideoCapture(path_video)\n",
    "        if cap.isOpened():\n",
    "            rate = cap.get(5)\n",
    "            FrameNumber = cap.get(7)\n",
    "            duration = (FrameNumber/rate)\n",
    "            durations.append(duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dir_train = os.path.join(dir_vision, 'train')\n",
    "dir_val = os.path.join(dir_vision, 'val')\n",
    "if not os.path.exists(dir_train): os.mkdir(dir_train)\n",
    "if not os.path.exists(dir_val): os.mkdir(dir_val)\n",
    "\n",
    "for name in names_vision:\n",
    "    g = os.walk(os.path.join(dir_10s, name))\n",
    "    dir_target_train = os.path.join(dir_train, name)\n",
    "    dir_target_val = os.path.join(dir_val, name)\n",
    "    if not os.path.exists(dir_target_train): os.mkdir(dir_target_train)\n",
    "    if not os.path.exists(dir_target_val): os.mkdir(dir_target_val)\n",
    "\n",
    "    paths_video = []\n",
    "    for path,dir_list,file_list in g:\n",
    "        for file_name in file_list:\n",
    "            path_video = os.path.join(path, file_name)\n",
    "            paths_video.append(path_video)\n",
    "    paths_train, paths_val = train_test_split(paths_video, test_size=0.2)\n",
    "    for num, path_train in enumerate(paths_train):\n",
    "        shutil.copyfile(path_train, os.path.join(dir_target_train, '{}_{}.mp4'.format(name, num)))\n",
    "    for num, path_val in enumerate(paths_val):\n",
    "        shutil.copyfile(path_val, os.path.join(dir_target_val, '{}_{}.mp4'.format(name, num)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dir_train = os.path.join(dir_vision, 'train')\n",
    "dir_val = os.path.join(dir_vision, 'val')\n",
    "if not os.path.exists(dir_train): os.mkdir(dir_train)\n",
    "if not os.path.exists(dir_val): os.mkdir(dir_val)\n",
    "\n",
    "for name in names_vision:\n",
    "    g = os.walk(os.path.join(dir_10s, name))\n",
    "    dir_target_train = os.path.join(dir_train, name)\n",
    "    dir_target_val = os.path.join(dir_val, name)\n",
    "    if not os.path.exists(dir_target_train): os.mkdir(dir_target_train)\n",
    "    if not os.path.exists(dir_target_val): os.mkdir(dir_target_val)\n",
    "\n",
    "    paths_video = []\n",
    "    for path,dir_list,file_list in g:\n",
    "        for file_name in file_list:\n",
    "            path_video = os.path.join(path, file_name)\n",
    "            paths_video.append(path_video)\n",
    "    paths_train, paths_val = train_test_split(paths_video, test_size=0.2)\n",
    "    for num, path_train in enumerate(paths_train):\n",
    "        shutil.copyfile(path_train, os.path.join(dir_target_train, '{}_{}.mp4'.format(name, num)))\n",
    "    for num, path_val in enumerate(paths_val):\n",
    "        shutil.copyfile(path_val, os.path.join(dir_target_val, '{}_{}.mp4'.format(name, num)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "448a91a858e0e0f6420cef597fef2a4601b29339f1466ecc2ae63d7089960f16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
